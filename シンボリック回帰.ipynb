{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MO230101/test/blob/main/%E3%82%B7%E3%83%B3%E3%83%9C%E3%83%AA%E3%83%83%E3%82%AF%E5%9B%9E%E5%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "collapsed": true,
        "id": "5wcgcXLDZQbj",
        "outputId": "4c8d1d94-f100-4d29-bb65-467c4bf92be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.0, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb12e810410>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-06a49f73ffb2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0my_pred_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gplearn/genetic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             population = Parallel(n_jobs=n_jobs,\n\u001b[0m\u001b[1;32m    477\u001b[0m                                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 delayed(_parallel_evolve)(n_programs[i],\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('Swelling_RDKit_DSC_MSEGPMGnodry_Top10_250502.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# 特徴量のスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# カスタム関数定義 (例: 二乗関数と立方根関数)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square,\n",
        "                                     arity=1,\n",
        "                                     name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt,\n",
        "                                   arity=1,\n",
        "                                   name='cbrt')\n",
        "\n",
        "# 精度評価関数（分類）\n",
        "def binary_accuracy_scorer(estimator, X, y_true):\n",
        "    y_pred = estimator.predict(X)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    return accuracy_score(y_true, y_pred_binary)\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', square_function]\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [3000, 5000],\n",
        "    'generations': [300, 500],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.0, 1e-5], # 0 を追加\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t59rOTJiRLjs",
        "outputId": "d906803a-0237-4227-e33a-6364ec5ef987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-652c37e4f48e>:49: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19148dd10>, <gplearn.functions._Function object at 0x7fb1368798d0>, <gplearn.functions._Function object at 0x7fb135e9d6d0>, <gplearn.functions._Function object at 0x7fb135e9e310>]}\n",
            "\n",
            "Trial 2/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 1000, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19148dd10>, <gplearn.functions._Function object at 0x7fb1368798d0>, <gplearn.functions._Function object at 0x7fb135e9d6d0>, <gplearn.functions._Function object at 0x7fb135e9e310>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19148dd10>, <gplearn.functions._Function object at 0x7fb1368798d0>, <gplearn.functions._Function object at 0x7fb135e9d6d0>, <gplearn.functions._Function object at 0x7fb135e9e310>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 1000, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19148dd10>, <gplearn.functions._Function object at 0x7fb1368798d0>, <gplearn.functions._Function object at 0x7fb135e9d6d0>, <gplearn.functions._Function object at 0x7fb135e9e310>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19148dd10>, <gplearn.functions._Function object at 0x7fb1368798d0>, <gplearn.functions._Function object at 0x7fb135e9d6d0>, <gplearn.functions._Function object at 0x7fb135e9e310>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.625\n",
            "  Precision: 0.625\n",
            "  Recall: 1.0\n",
            "  F1-score: 0.7692307692307693\n",
            "  AUC: 0.5\n",
            "  Features: ['CPMGH2O_109.73048', 'CPMGH2O_117.85752', 'CPMGH2O_121.92104', 'CPMGH2O_130.04808', 'CPMGH2O_146.30216']\n",
            "  Equation: 0.715\n",
            "  Parameters: {'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19148dd10>, <gplearn.functions._Function object at 0x7fb1368798d0>, <gplearn.functions._Function object at 0x7fb135e9d6d0>, <gplearn.functions._Function object at 0x7fb135e9e310>]}\n"
          ]
        }
      ],
      "source": [
        "#20250502 for swelling　スケーリング削除\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# from sklearn.preprocessing import StandardScaler # 削除\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('Swelling_RDKit_DSC_MSEGPMGnodry_Top10_250502.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# # 特徴量のスケーリング # 削除\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = X_train.copy() # スケーリングしない場合は元のDataFrameをコピー\n",
        "X_test_scaled_df = X_test.copy()   # スケーリングしない場合は元のDataFrameをコピー\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function] # 関数オブジェクトを直接指定\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [3, 5, 10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [1000, 3000],\n",
        "    'generations': [500, 1000],\n",
        "    'tournament_size': [10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.01],\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6SQnRhjnsi1",
        "outputId": "a4aa440a-b0c7-437e-e6ad-3bd8df8c7eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb13461a110>, <gplearn.functions._Function object at 0x7fb11d226d10>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-7b8fde7ea9e1>:49: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 500, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb13461a110>, <gplearn.functions._Function object at 0x7fb11d226d10>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb13461a110>, <gplearn.functions._Function object at 0x7fb11d226d10>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 500, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb13461a110>, <gplearn.functions._Function object at 0x7fb11d226d10>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb13461a110>, <gplearn.functions._Function object at 0x7fb11d226d10>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.875\n",
            "  Precision: 0.8333333333333334\n",
            "  Recall: 1.0\n",
            "  F1-score: 0.9090909090909091\n",
            "  AUC: 1.0\n",
            "  Features: ['MaxPartialCharge', 'NHOHCount', 'NumHDonors', 'CPMGH2O_109.73048', 'CPMGH2O_117.85752', 'CPMGH2O_121.92104', 'CPMGH2O_130.04808', 'CPMGH2O_146.30216', 'CPMGH2O_180.84208', 'CPMGH2O_256.0172']\n",
            "  Equation: sqrt(mul(neg(cbrt(abs(sub(0.583, NumHDonors)))), sub(mul(cbrt(NHOHCount), -0.420), neg(sub(sub(mul(mul(mul(neg(CPMGH2O_146.30216), sub(CPMGH2O_109.73048, CPMGH2O_256.0172)), add(neg(CPMGH2O_109.73048), sqrt(MaxPartialCharge))), add(cbrt(-0.233), cbrt(CPMGH2O_256.0172))), add(mul(inv(CPMGH2O_121.92104), mul(-0.223, CPMGH2O_117.85752)), sqrt(-0.290))), neg(cbrt(abs(sub(0.583, NumHDonors)))))))))\n",
            "  Parameters: {'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb13461a110>, <gplearn.functions._Function object at 0x7fb11d226d10>]}\n"
          ]
        }
      ],
      "source": [
        "#20250502 for swelling　スケーリング削除 カスタム関数シンプル化\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# from sklearn.preprocessing import StandardScaler # 削除\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('Swelling_RDKit_DSC_MSEGPMGnodry_Top10_250502.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# # 特徴量のスケーリング # 削除\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = X_train.copy() # スケーリングしない場合は元のDataFrameをコピー\n",
        "X_test_scaled_df = X_test.copy()   # スケーリングしない場合は元のDataFrameをコピー\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', square_function, cbrt_function]\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [3, 5, 10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [500, 1000, 3000],\n",
        "    'generations': [50, 100, 300],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.0001, 0.001, 0.01],\n",
        "   }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIe62vPtGlBO",
        "outputId": "4fced738-e82b-443d-bb8d-e5ed19b329a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.2\n",
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 50, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7c76191e0110>, 'inv', 'neg', <gplearn.functions._Function object at 0x7c7619b0f050>, <gplearn.functions._Function object at 0x7c761c328390>, <gplearn.functions._Function object at 0x7c761a2cce90>, <gplearn.functions._Function object at 0x7c76191cff10>, <gplearn.functions._Function object at 0x7c76191cffd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-35244e505ac8>:46: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "<ipython-input-1-35244e505ac8>:55: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-1-35244e505ac8>:55: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 1.0\n",
            "  Precision: 1.0\n",
            "  Recall: 1.0\n",
            "  F1-score: 1.0\n",
            "  AUC: 1.0\n",
            "  Features: ['MaxPartialCharge', 'NHOHCount', 'NumHDonors', 'Mobile_water_109ms', 'Mobile_water_118ms', 'Mobile_water_122ms', 'Mobile_water_130ms', 'Mobile_water_146ms', 'Mobile_water_181ms', 'Mobile_water_256ms']\n",
            "  Equation: exp(mul2(log(exp(log(neg(NHOHCount)))), Mobile_water_181ms))\n",
            "  Parameters: {'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 50, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7c76191e0110>, 'inv', 'neg', <gplearn.functions._Function object at 0x7c7619b0f050>, <gplearn.functions._Function object at 0x7c761c328390>, <gplearn.functions._Function object at 0x7c761a2cce90>, <gplearn.functions._Function object at 0x7c76191cff10>, <gplearn.functions._Function object at 0x7c76191cffd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-35244e505ac8>:55: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-1-35244e505ac8>:55: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n"
          ]
        }
      ],
      "source": [
        "#20250506 for swelling　スケーリング削除 カスタム関数シンプル化　再トライ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# from sklearn.preprocessing import StandardScaler # 削除\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('Swelling_RDKit_DSC_MSEGPMGnodry_Top10_250502.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# # 特徴量のスケーリング # 削除\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = X_train.copy() # スケーリングしない場合は元のDataFrameをコピー\n",
        "X_test_scaled_df = X_test.copy()   # スケーリングしない場合は元のDataFrameをコピー\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10) # 無限大を大きな有限数に置換\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "# sqrt_function の定義は残しておいても問題ありませんが、function_set から削除します\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', log_function, 'inv', 'neg',\n",
        "                square_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                multiply3_function,\n",
        "                exp_function]\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [5000],\n",
        "    'generations': [50],\n",
        "    'tournament_size': [5],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.05],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.01],\n",
        "   }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQhkvL8Uu3mI",
        "outputId": "c45bcc22-5982-4efc-e07b-659ffc4932d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-2732d5c531f5>:46: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "<ipython-input-2-2732d5c531f5>:55: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-2-2732d5c531f5>:55: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.05, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7aaef2437190>, 'inv', 'neg', <gplearn.functions._Function object at 0x7aaf9c244e10>, <gplearn.functions._Function object at 0x7aaef12b36d0>, <gplearn.functions._Function object at 0x7aaef2435510>, <gplearn.functions._Function object at 0x7aaef2436f10>, <gplearn.functions._Function object at 0x7aaef2436650>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.07, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 50, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7aaef2437190>, 'inv', 'neg', <gplearn.functions._Function object at 0x7aaf9c244e10>, <gplearn.functions._Function object at 0x7aaef12b36d0>, <gplearn.functions._Function object at 0x7aaef2435510>, <gplearn.functions._Function object at 0x7aaef2436f10>, <gplearn.functions._Function object at 0x7aaef2436650>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7aaef2437190>, 'inv', 'neg', <gplearn.functions._Function object at 0x7aaf9c244e10>, <gplearn.functions._Function object at 0x7aaef12b36d0>, <gplearn.functions._Function object at 0x7aaef2435510>, <gplearn.functions._Function object at 0x7aaef2436f10>, <gplearn.functions._Function object at 0x7aaef2436650>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#20250511 for swelling　スケーリング削除 カスタム関数シンプル化　再トライ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# from sklearn.preprocessing import StandardScaler # 削除\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('Swelling_RDKit_DSCafter0.6cut_MSEGPMGnodry_Top10_250511.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# # 特徴量のスケーリング # 削除\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = X_train.copy() # スケーリングしない場合は元のDataFrameをコピー\n",
        "X_test_scaled_df = X_test.copy()   # スケーリングしない場合は元のDataFrameをコピー\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10) # 無限大を大きな有限数に置換\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "# sqrt_function の定義は残しておいても問題ありませんが、function_set から削除します\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', log_function, 'inv', 'neg',\n",
        "                square_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                multiply3_function,\n",
        "                exp_function]\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [5000],\n",
        "    'generations': [10, 50, 250, 500],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.05],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.01, 0.03, 0.05, 0.07],\n",
        "   }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGQy9T7QSkpO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w3-NfiDMvbgG",
        "outputId": "642ce29c-e982-49cd-b282-89abfc7d44a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "\n",
            "Trial 1/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 20, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-9c2329a11484>:49: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 20, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 6/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 7/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 8/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 20, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 9/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 20, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 10/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.75\n",
            "  Precision: 1.0\n",
            "  Recall: 0.5\n",
            "  F1-score: 0.6666666666666666\n",
            "  AUC: 0.75\n",
            "  Features: ['PEOE_VSA14', 'SlogP_VSA1', 'fr_COO', 'fr_COO2', 'Mobile_water_93ms', 'Mobile_water_130ms', 'Mobile_water_158ms', 'Mobile_water_195ms', 'Mobile_water_375ms', 'Mobile_chains_191ms']\n",
            "  Equation: abs(mul2(sub(Mobile_chains_191ms, fr_COO), -0.425))\n",
            "  Parameters: {'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 4000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7c7604dde4d0>, <gplearn.functions._Function object at 0x7c75f8984490>, <gplearn.functions._Function object at 0x7c75f8985bd0>, <gplearn.functions._Function object at 0x7c75f8985450>]}\n"
          ]
        }
      ],
      "source": [
        "#20250502 for HSQC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HSQC_RDKit_DSC_CPMGMSEnodry_Top10_Features_250510.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# 特徴量のスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function] # 関数オブジェクトを直接指定\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [5, 10, 20],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [4000],\n",
        "    'generations': [300, 500],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.01],\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 10\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X5Bd4sjEZW2",
        "outputId": "fc0e9715-f56d-44b6-db4f-6fcadc10824d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-6cac57b1c934>:41: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b37c911de50>, <gplearn.functions._Function object at 0x7b37bf251150>]}\n",
            "\n",
            "Trial 2/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 500, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b37c911de50>, <gplearn.functions._Function object at 0x7b37bf251150>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b37c911de50>, <gplearn.functions._Function object at 0x7b37bf251150>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 500, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b37c911de50>, <gplearn.functions._Function object at 0x7b37bf251150>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b37c911de50>, <gplearn.functions._Function object at 0x7b37bf251150>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.5\n",
            "  Precision: 0.5\n",
            "  Recall: 0.25\n",
            "  F1-score: 0.3333333333333333\n",
            "  AUC: 0.1875\n",
            "  Features: ['PEOE_VSA14', 'CPMGH2O_158.49272', 'CPMGH2O_195.0644']\n",
            "  Equation: mul(abs(mul(abs(sub(sqrt(PEOE_VSA14), sqrt(0.856))), sqrt(sub(log(add(cbrt(cbrt(CPMGH2O_195.0644)), CPMGH2O_158.49272)), cbrt(square(abs(sqrt(mul(sqrt(square(log(neg(PEOE_VSA14)))), sqrt(sub(log(add(cbrt(cbrt(CPMGH2O_195.0644)), sqrt(sub(log(add(cbrt(abs(sub(sqrt(PEOE_VSA14), sqrt(0.856)))), CPMGH2O_158.49272)), cbrt(inv(PEOE_VSA14)))))), log(PEOE_VSA14)))))))))))), abs(sub(square(abs(log(PEOE_VSA14))), cbrt(log(CPMGH2O_158.49272)))))\n",
            "  Parameters: {'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 500, 'parsimony_coefficient': 0.0001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b37c911de50>, <gplearn.functions._Function object at 0x7b37bf251150>]}\n"
          ]
        }
      ],
      "source": [
        "#20250503 for HSQC - スケーリング削除 カスタム関数シンプル化\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HSQC_RDKit_DSC_CPMGMSEnodry_Top10_Features_250502.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', square_function, cbrt_function]\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [3, 5, 10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [500, 1000, 3000],\n",
        "    'generations': [50, 100, 300],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.0001, 0.001, 0.01],\n",
        "   }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train, y_train) # スケール前のデータを使用\n",
        "    X_test_sel = selector.transform(X_test) # スケール前のデータを使用\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awxj9Vz_9alR",
        "outputId": "eb10c3c3-18d0-4795-a2c1-fd03280475e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b379d8a1c10>, <gplearn.functions._Function object at 0x7b379c91ff90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-13fd8987bcba>:49: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b379d8a1c10>, <gplearn.functions._Function object at 0x7b379c91ff90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 50, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b379d8a1c10>, <gplearn.functions._Function object at 0x7b379c91ff90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b379d8a1c10>, <gplearn.functions._Function object at 0x7b379c91ff90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5/5 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b379d8a1c10>, <gplearn.functions._Function object at 0x7b379c91ff90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.375\n",
            "  Precision: 0.0\n",
            "  Recall: 0.0\n",
            "  F1-score: 0.0\n",
            "  AUC: 0.46875\n",
            "  Features: ['PEOE_VSA14', 'SlogP_VSA1', 'fr_COO', 'fr_COO2', 'CPMGH2O_93.4764', 'CPMGH2O_130.04808', 'CPMGH2O_158.49272', 'CPMGH2O_195.0644', 'CPMGH2O_375.89104', 'CPMGD2O_191.00088']\n",
            "  Equation: abs(abs(abs(log(PEOE_VSA14))))\n",
            "  Parameters: {'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7b379d8a1c10>, <gplearn.functions._Function object at 0x7b379c91ff90>]}\n"
          ]
        }
      ],
      "source": [
        "#20250502 for HSQC　スケーリング削除 カスタム関数シンプル化2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# from sklearn.preprocessing import StandardScaler # 削除\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HSQC_RDKit_DSC_CPMGMSEnodry_Top10_Features_250502.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# # 特徴量のスケーリング # 削除\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = X_train.copy() # スケーリングしない場合は元のDataFrameをコピー\n",
        "X_test_scaled_df = X_test.copy()   # スケーリングしない場合は元のDataFrameをコピー\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', square_function, cbrt_function]\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [5, 10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [5000],\n",
        "    'generations': [50, 100, 300],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.01],\n",
        "   }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiimkx3tfYny",
        "outputId": "709d2d21-f394-4bb5-b776-9d34ef6ddc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-7366e200fdea>:46: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "<ipython-input-7-7366e200fdea>:55: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-7-7366e200fdea>:55: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 50, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x78a0378bdcd0>, 'inv', 'neg', <gplearn.functions._Function object at 0x78a054c33fd0>, <gplearn.functions._Function object at 0x78a054c33210>, <gplearn.functions._Function object at 0x78a0378ec110>, <gplearn.functions._Function object at 0x78a0378ef050>, <gplearn.functions._Function object at 0x78a03654df90>]}\n",
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.375\n",
            "  Precision: 0.0\n",
            "  Recall: 0.0\n",
            "  F1-score: 0.0\n",
            "  AUC: 0.46875\n",
            "  Features: ['PEOE_VSA14', 'SlogP_VSA1', 'fr_COO', 'fr_COO2', 'CPMGH2O_93.4764', 'CPMGH2O_130.04808', 'CPMGH2O_158.49272', 'CPMGH2O_195.0644', 'CPMGH2O_375.89104', 'CPMGD2O_191.00088']\n",
            "  Equation: abs(log(abs(PEOE_VSA14)))\n",
            "  Parameters: {'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 50, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x78a0378bdcd0>, 'inv', 'neg', <gplearn.functions._Function object at 0x78a054c33fd0>, <gplearn.functions._Function object at 0x78a054c33210>, <gplearn.functions._Function object at 0x78a0378ec110>, <gplearn.functions._Function object at 0x78a0378ef050>, <gplearn.functions._Function object at 0x78a03654df90>]}\n"
          ]
        }
      ],
      "source": [
        "#20250506 for HSQC　スケーリング削除 カスタム関数シンプル化　再トライ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# from sklearn.preprocessing import StandardScaler # 削除\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HSQC_RDKit_DSC_CPMGMSEnodry_Top10_Features_250502.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# # 特徴量のスケーリング # 削除\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = X_train.copy() # スケーリングしない場合は元のDataFrameをコピー\n",
        "X_test_scaled_df = X_test.copy()   # スケーリングしない場合は元のDataFrameをコピー\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10) # 無限大を大きな有限数に置換\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "# sqrt_function の定義は残しておいても問題ありませんが、function_set から削除します\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', log_function, 'inv', 'neg',\n",
        "                square_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                multiply3_function,\n",
        "                exp_function]\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [5000],\n",
        "    'generations': [50],\n",
        "    'tournament_size': [5],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.05],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.01],\n",
        "   }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prQhvZjpW36i",
        "outputId": "c43ae380-6ed7-4c66-fd29-638446e22e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "\n",
            "Trial 1/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-38685a8f7511>:49: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 300, 'parsimony_coefficient': 0.1, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 300, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n",
            "\n",
            "Trial 5/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 6/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 7/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.1, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 3, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 8/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.1, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n",
            "\n",
            "Trial 9/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 300, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 10/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 300, 'parsimony_coefficient': 0.1, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.75\n",
            "  Precision: 0.6666666666666666\n",
            "  Recall: 0.6666666666666666\n",
            "  F1-score: 0.6666666666666666\n",
            "  AUC: 0.7666666666666666\n",
            "  Features: ['BCUT2D_MWHI', 'PEOE_VSA13', 'VSA_EState10', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'DSC_area', 'DSC_peak_height', 'MSEH2O_0.12992', 'CPMGD2O_119.88928']\n",
            "  Equation: abs(mul2(fr_Al_COO, VSA_EState10))\n",
            "  Parameters: {'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fc3ec1bae50>, <gplearn.functions._Function object at 0x7fc3c4507610>, <gplearn.functions._Function object at 0x7fc3cc8d7110>, <gplearn.functions._Function object at 0x7fc3bfc95790>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "#20250502 for HNCO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# 特徴量のスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function] # 関数オブジェクトを直接指定\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [3, 5, 10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [300, 1000, 3000],\n",
        "    'generations': [300, 500],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.01, 0.1],\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 10\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTEd28s_9J_8",
        "outputId": "e022b227-5283-4d59-ac9c-75aa16d051e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.2\n",
            "\n",
            "Trial 1/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 2000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'max_depth': 10, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-226ffadf6cf7>:41: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 2000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'max_depth': 7, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 2000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'max_depth': 7, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'max_depth': 10, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 2000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'max_depth': 10, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 6/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'max_depth': 7, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 7/10 with parameters:\n",
            "{'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 2000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'max_depth': 7, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 8/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'max_depth': 10, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 9/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 2000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 0.9, 'max_depth': 5, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 10/10 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 3000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'max_depth': 5, 'generations': 300, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.75\n",
            "  Precision: 0.6666666666666666\n",
            "  Recall: 0.6666666666666666\n",
            "  F1-score: 0.6666666666666666\n",
            "  AUC: 0.7666666666666666\n",
            "  Features: ['BCUT2D_MWHI', 'PEOE_VSA13', 'VSA_EState10', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'DSC_area', 'DSC_peak_height', 'MSEH2O_0.12992', 'CPMGD2O_119.88928']\n",
            "  Equation: abs(mul2(fr_Al_COO, VSA_EState10))\n",
            "  Parameters: {'tournament_size': 10, 'stopping_criteria': 0.05, 'population_size': 2000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.03, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 0.9, 'max_depth': 7, 'generations': 500, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7fb19c1b8450>, <gplearn.functions._Function object at 0x7fb19ae057d0>, <gplearn.functions._Function object at 0x7fb1e8640e90>, <gplearn.functions._Function object at 0x7fb19beaedd0>]}\n"
          ]
        }
      ],
      "source": [
        "#20250502 for HNCO - スケーリング除去\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function] # 関数オブジェクトを直接指定\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [5, 10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [2000, 3000],\n",
        "    'generations': [300, 500],\n",
        "    'tournament_size': [5, 10],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.03],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [0.9],\n",
        "    'parsimony_coefficient': [0.001, 0.01],\n",
        "    'max_depth': [5, 7, 10], # max_depth を追加\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 10\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train, y_train) # スケール前のデータを使用\n",
        "    X_test_sel = selector.transform(X_test) # スケール前のデータを使用\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "collapsed": true,
        "id": "eJQP49NcwbI3",
        "outputId": "05da7775-9df7-433d-e6e2-5c6a776fd225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.2\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4856776e777f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# データ読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'Unnamed: 0'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CA1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv'"
          ]
        }
      ],
      "source": [
        "#20250502 for HNCO - スケーリング除去, カスタム関数複雑化\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def protected_cube(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**3, np.sign(x) * 1e10)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), np.inf)\n",
        "\n",
        "tanh_function = make_function(function=np.tanh, arity=1, name='tanh')\n",
        "\n",
        "def protected_sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "cube_function = make_function(function=protected_cube, arity=1, name='cube')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "sigmoid_function = make_function(function=protected_sigmoid, arity=1, name='sigmoid')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                cube_function, multiply3_function,\n",
        "                exp_function, tanh_function,\n",
        "                sigmoid_function] # 全てのカスタム関数を追加\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train, y_train) # スケール前のデータを使用\n",
        "    X_test_sel = selector.transform(X_test) # スケール前のデータを使用\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "collapsed": true,
        "id": "bqusuLLKuSNK",
        "outputId": "9f8dfecd-7b0d-4852-a2a9-0d5c5e7aa188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "\n",
            "Trial 1/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.01, 'p_point_mutation': 0.01, 'p_hoist_mutation': 0.01, 'p_crossover': 0.9, 'n_features_to_select': 20, 'max_samples': 1.0, 'generations': 20, 'function_set': ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg', <gplearn.functions._Function object at 0x7f1d0c06fd90>, <gplearn.functions._Function object at 0x7f1d0c06f8d0>, <gplearn.functions._Function object at 0x7f1d0c06f190>, <gplearn.functions._Function object at 0x7f1cf4cbf490>, <gplearn.functions._Function object at 0x7f1cf9bace10>, <gplearn.functions._Function object at 0x7f1d0c06f590>, <gplearn.functions._Function object at 0x7f1d002c3e50>, <gplearn.functions._Function object at 0x7f1d0507e7d0>, <gplearn.functions._Function object at 0x7f1d002c3850>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-c75a933603cd>:42: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "<ipython-input-4-c75a933603cd>:51: RuntimeWarning: overflow encountered in exp\n",
            "  return np.where(x < 100, np.exp(x), np.inf)\n",
            "<ipython-input-4-c75a933603cd>:51: RuntimeWarning: overflow encountered in exp\n",
            "  return np.where(x < 100, np.exp(x), np.inf)\n",
            "<ipython-input-4-c75a933603cd>:51: RuntimeWarning: overflow encountered in exp\n",
            "  return np.where(x < 100, np.exp(x), np.inf)\n",
            "/usr/local/lib/python3.11/dist-packages/gplearn/functions.py:46: RuntimeWarning: invalid value encountered in add\n",
            "  return self.function(*args)\n",
            "<ipython-input-4-c75a933603cd>:51: RuntimeWarning: overflow encountered in exp\n",
            "  return np.where(x < 100, np.exp(x), np.inf)\n",
            "<ipython-input-4-c75a933603cd>:51: RuntimeWarning: overflow encountered in exp\n",
            "  return np.where(x < 100, np.exp(x), np.inf)\n",
            "/usr/local/lib/python3.11/dist-packages/gplearn/functions.py:46: RuntimeWarning: invalid value encountered in multiply\n",
            "  return self.function(*args)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c75a933603cd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     if y_type == \"multiclass\" or (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ],
      "source": [
        "#20250502 for HNCO - スケーリング除去, カスタム関数複雑化2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# カスタム関数定義\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def protected_cube(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**3, np.sign(x) * 1e10)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), np.inf)\n",
        "\n",
        "tanh_function = make_function(function=np.tanh, arity=1, name='tanh')\n",
        "\n",
        "def protected_sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "cube_function = make_function(function=protected_cube, arity=1, name='cube')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "sigmoid_function = make_function(function=protected_sigmoid, arity=1, name='sigmoid')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', 'sqrt', 'log', 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                cube_function, multiply3_function,\n",
        "                exp_function, tanh_function,\n",
        "                sigmoid_function] # 全てのカスタム関数を追加\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [20],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [1000],\n",
        "    'generations': [20],\n",
        "    'tournament_size': [20],\n",
        "    'stopping_criteria': [0.0],\n",
        "    'p_crossover': [0.9],\n",
        "    'p_subtree_mutation': [0.01],\n",
        "    'p_hoist_mutation': [0.01],\n",
        "    'p_point_mutation': [0.01],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.001],\n",
        " }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 10\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train, y_train) # スケール前のデータを使用\n",
        "    X_test_sel = selector.transform(X_test) # スケール前のデータを使用\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Eg7Vc-RldqB",
        "outputId": "40c057bf-22e1-4226-8dba-762212594824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "NaNを含む特徴量の数:\n",
            " BCUT2D_MWHI          0\n",
            "Ipc                  0\n",
            "PEOE_VSA13           0\n",
            "EState_VSA5          0\n",
            "VSA_EState10         0\n",
            "fr_Al_COO            0\n",
            "fr_Al_OH             0\n",
            "fr_Al_OH_noTert      0\n",
            "DSC_area             0\n",
            "DSC_peak_height      0\n",
            "MSEH2O_0.0992        0\n",
            "MSEH2O_0.12992       0\n",
            "MSEH2O_0.14528       0\n",
            "MSEH2O_0.15424       0\n",
            "MSED2O_0.0992        0\n",
            "CPMGH2O_243.82664    0\n",
            "CPMGD2O_46.74592     0\n",
            "CPMGD2O_93.4764      0\n",
            "CPMGD2O_119.88928    0\n",
            "CPMGD2O_264.14424    0\n",
            "dtype: int64\n",
            "NaNを含むターゲット変数の数: 0\n",
            "\n",
            "Trial 1/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 1.0, 'generations': 20, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1d2baa1010>, <gplearn.functions._Function object at 0x7f1d2baa0d90>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf004a9d0>, <gplearn.functions._Function object at 0x7f1cf19d75d0>, <gplearn.functions._Function object at 0x7f1cef25bf50>, <gplearn.functions._Function object at 0x7f1d2baa2350>, <gplearn.functions._Function object at 0x7f1d2baa11d0>, <gplearn.functions._Function object at 0x7f1d2baa0f90>, <gplearn.functions._Function object at 0x7f1d2baa0d50>, <gplearn.functions._Function object at 0x7f1d2baa0e50>, <gplearn.functions._Function object at 0x7f1d2baa2d50>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-991b7af3ef6b>:50: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "<ipython-input-10-991b7af3ef6b>:62: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-10-991b7af3ef6b>:62: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-10-991b7af3ef6b>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.625\n",
            "  Precision: 0.5\n",
            "  Recall: 0.6666666666666666\n",
            "  F1-score: 0.5714285714285714\n",
            "  AUC: 0.5333333333333333\n",
            "  Features: ['BCUT2D_MWHI', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'DSC_peak_height']\n",
            "  Equation: square(sigmoid(sub(sub(abs(DSC_peak_height), sub(square(fr_Al_OH), sub(abs(DSC_peak_height), sub(square(sigmoid(sub(div(inv(BCUT2D_MWHI), cbrt(fr_Al_OH)), sqrt(0.894)))), div(inv(BCUT2D_MWHI), cbrt(fr_Al_OH)))))), 0.894)))\n",
            "  Parameters: {'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 5, 'max_samples': 1.0, 'generations': 20, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1d2baa1010>, <gplearn.functions._Function object at 0x7f1d2baa0d90>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf004a9d0>, <gplearn.functions._Function object at 0x7f1cf19d75d0>, <gplearn.functions._Function object at 0x7f1cef25bf50>, <gplearn.functions._Function object at 0x7f1d2baa2350>, <gplearn.functions._Function object at 0x7f1d2baa11d0>, <gplearn.functions._Function object at 0x7f1d2baa0f90>, <gplearn.functions._Function object at 0x7f1d2baa0d50>, <gplearn.functions._Function object at 0x7f1d2baa0e50>, <gplearn.functions._Function object at 0x7f1d2baa2d50>]}\n"
          ]
        }
      ],
      "source": [
        "#20250502 for HNCO - スケーリング除去, カスタム関数複雑化2→修正版\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込みと NaN 処理\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# NaN のチェック\n",
        "print(\"NaNを含む特徴量の数:\\n\", X.isnull().sum())\n",
        "print(\"NaNを含むターゲット変数の数:\", y.isnull().sum())\n",
        "\n",
        "# NaN の処理 (平均値で補完)\n",
        "X = X.fillna(X.mean())\n",
        "y = y.fillna(y.mean())\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def protected_cube(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**3, np.sign(x) * 1e10)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10) # 無限大を大きな有限数に置換\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
        "\n",
        "def protected_sqrt(x):\n",
        "    return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
        "\n",
        "def protected_tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def protected_sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -100, 100))) # オーバーフロー対策としてクリップ\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "cube_function = make_function(function=protected_cube, arity=1, name='cube')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "sqrt_function = make_function(function=protected_sqrt, arity=1, name='sqrt')\n",
        "tanh_function = make_function(function=protected_tanh, arity=1, name='tanh')\n",
        "sigmoid_function = make_function(function=protected_sigmoid, arity=1, name='sigmoid')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', sqrt_function, log_function, 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                cube_function, multiply3_function,\n",
        "                exp_function, tanh_function,\n",
        "                sigmoid_function]\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [5],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [1000],\n",
        "    'generations': [20],\n",
        "    'tournament_size': [20],\n",
        "    'stopping_criteria': [0.0],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.05],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.001], # 少し大きめの値を設定\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 10\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train, y_train) # スケール前のデータを使用\n",
        "    X_test_sel = selector.transform(X_test) # スケール前のデータを使用\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw8TcuIP1anA",
        "outputId": "54575a57-cc78-4872-c37c-8ddb084b8516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "NaNを含む特徴量の数:\n",
            " BCUT2D_MWHI          0\n",
            "Ipc                  0\n",
            "PEOE_VSA13           0\n",
            "EState_VSA5          0\n",
            "VSA_EState10         0\n",
            "fr_Al_COO            0\n",
            "fr_Al_OH             0\n",
            "fr_Al_OH_noTert      0\n",
            "DSC_area             0\n",
            "DSC_peak_height      0\n",
            "MSEH2O_0.0992        0\n",
            "MSEH2O_0.12992       0\n",
            "MSEH2O_0.14528       0\n",
            "MSEH2O_0.15424       0\n",
            "MSED2O_0.0992        0\n",
            "CPMGH2O_243.82664    0\n",
            "CPMGD2O_46.74592     0\n",
            "CPMGD2O_93.4764      0\n",
            "CPMGD2O_119.88928    0\n",
            "CPMGD2O_264.14424    0\n",
            "dtype: int64\n",
            "NaNを含むターゲット変数の数: 0\n",
            "\n",
            "Trial 1/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 20, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1ced9168d0>, <gplearn.functions._Function object at 0x7f1ced917a50>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf82101d0>, <gplearn.functions._Function object at 0x7f1cefe80310>, <gplearn.functions._Function object at 0x7f1cf18e7210>, <gplearn.functions._Function object at 0x7f1cf7931e10>, <gplearn.functions._Function object at 0x7f1ced9174d0>, <gplearn.functions._Function object at 0x7f1ced916310>, <gplearn.functions._Function object at 0x7f1ced915c90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-3785316c0881>:50: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "<ipython-input-33-3785316c0881>:62: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-33-3785316c0881>:62: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 3000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 20, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1ced9168d0>, <gplearn.functions._Function object at 0x7f1ced917a50>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf82101d0>, <gplearn.functions._Function object at 0x7f1cefe80310>, <gplearn.functions._Function object at 0x7f1cf18e7210>, <gplearn.functions._Function object at 0x7f1cf7931e10>, <gplearn.functions._Function object at 0x7f1ced9174d0>, <gplearn.functions._Function object at 0x7f1ced916310>, <gplearn.functions._Function object at 0x7f1ced915c90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 5000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 20, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1ced9168d0>, <gplearn.functions._Function object at 0x7f1ced917a50>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf82101d0>, <gplearn.functions._Function object at 0x7f1cefe80310>, <gplearn.functions._Function object at 0x7f1cf18e7210>, <gplearn.functions._Function object at 0x7f1cf7931e10>, <gplearn.functions._Function object at 0x7f1ced9174d0>, <gplearn.functions._Function object at 0x7f1ced916310>, <gplearn.functions._Function object at 0x7f1ced915c90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1ced9168d0>, <gplearn.functions._Function object at 0x7f1ced917a50>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf82101d0>, <gplearn.functions._Function object at 0x7f1cefe80310>, <gplearn.functions._Function object at 0x7f1cf18e7210>, <gplearn.functions._Function object at 0x7f1cf7931e10>, <gplearn.functions._Function object at 0x7f1ced9174d0>, <gplearn.functions._Function object at 0x7f1ced916310>, <gplearn.functions._Function object at 0x7f1ced915c90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 3000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1ced9168d0>, <gplearn.functions._Function object at 0x7f1ced917a50>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf82101d0>, <gplearn.functions._Function object at 0x7f1cefe80310>, <gplearn.functions._Function object at 0x7f1cf18e7210>, <gplearn.functions._Function object at 0x7f1cf7931e10>, <gplearn.functions._Function object at 0x7f1ced9174d0>, <gplearn.functions._Function object at 0x7f1ced916310>, <gplearn.functions._Function object at 0x7f1ced915c90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 6/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 5000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1ced9168d0>, <gplearn.functions._Function object at 0x7f1ced917a50>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf82101d0>, <gplearn.functions._Function object at 0x7f1cefe80310>, <gplearn.functions._Function object at 0x7f1cf18e7210>, <gplearn.functions._Function object at 0x7f1cf7931e10>, <gplearn.functions._Function object at 0x7f1ced9174d0>, <gplearn.functions._Function object at 0x7f1ced916310>, <gplearn.functions._Function object at 0x7f1ced915c90>]}\n",
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.75\n",
            "  Precision: 0.6666666666666666\n",
            "  Recall: 0.6666666666666666\n",
            "  F1-score: 0.6666666666666666\n",
            "  AUC: 0.7\n",
            "  Features: ['BCUT2D_MWHI', 'PEOE_VSA13', 'VSA_EState10', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'DSC_area', 'DSC_peak_height', 'MSEH2O_0.12992', 'CPMGD2O_119.88928']\n",
            "  Equation: sqrt(sqrt(abs(mul3(DSC_area, sqrt(sub(neg(PEOE_VSA13), sqrt(fr_Al_OH))), sqrt(sqrt(abs(mul3(DSC_area, abs(sqrt(sub(neg(PEOE_VSA13), sqrt(fr_Al_OH)))), inv(sqrt(sqrt(neg(BCUT2D_MWHI))))))))))))\n",
            "  Parameters: {'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.001, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 20, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7f1ced9168d0>, <gplearn.functions._Function object at 0x7f1ced917a50>, 'inv', 'neg', <gplearn.functions._Function object at 0x7f1cf82101d0>, <gplearn.functions._Function object at 0x7f1cefe80310>, <gplearn.functions._Function object at 0x7f1cf18e7210>, <gplearn.functions._Function object at 0x7f1cf7931e10>, <gplearn.functions._Function object at 0x7f1ced9174d0>, <gplearn.functions._Function object at 0x7f1ced916310>, <gplearn.functions._Function object at 0x7f1ced915c90>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
            "<ipython-input-33-3785316c0881>:65: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n"
          ]
        }
      ],
      "source": [
        "#20250502 for HNCO - スケーリング除去, カスタム関数複雑化2→修正版2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込みと NaN 処理\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# NaN のチェック\n",
        "print(\"NaNを含む特徴量の数:\\n\", X.isnull().sum())\n",
        "print(\"NaNを含むターゲット変数の数:\", y.isnull().sum())\n",
        "\n",
        "# NaN の処理 (平均値で補完)\n",
        "X = X.fillna(X.mean())\n",
        "y = y.fillna(y.mean())\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def protected_cube(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**3, np.sign(x) * 1e10)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10) # 無限大を大きな有限数に置換\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
        "\n",
        "def protected_sqrt(x):\n",
        "    return np.where(x >= 0, np.sqrt(x), 0) # 負の値を 0 に置換\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "cube_function = make_function(function=protected_cube, arity=1, name='cube')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "sqrt_function = make_function(function=protected_sqrt, arity=1, name='sqrt')\n",
        "tanh_function = make_function(function=protected_tanh, arity=1, name='tanh')\n",
        "sigmoid_function = make_function(function=protected_sigmoid, arity=1, name='sigmoid')\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', sqrt_function, log_function, 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                cube_function, multiply3_function,\n",
        "                exp_function]\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [1000, 3000, 5000],\n",
        "    'generations': [20, 100],\n",
        "    'tournament_size': [20],\n",
        "    'stopping_criteria': [0.0],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.05],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.001], # 少し大きめの値を設定\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 10\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train, y_train) # スケール前のデータを使用\n",
        "    X_test_sel = selector.transform(X_test) # スケール前のデータを使用\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "74j6rlO2P1pO",
        "outputId": "7386ee1c-b984-4728-e14c-c47897a45e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "NaNを含む特徴量の数:\n",
            " BCUT2D_MWHI          0\n",
            "Ipc                  0\n",
            "PEOE_VSA13           0\n",
            "EState_VSA5          0\n",
            "VSA_EState10         0\n",
            "fr_Al_COO            0\n",
            "fr_Al_OH             0\n",
            "fr_Al_OH_noTert      0\n",
            "DSC_area             0\n",
            "DSC_peak_height      0\n",
            "MSEH2O_0.0992        0\n",
            "MSEH2O_0.12992       0\n",
            "MSEH2O_0.14528       0\n",
            "MSEH2O_0.15424       0\n",
            "MSED2O_0.0992        0\n",
            "CPMGH2O_243.82664    0\n",
            "CPMGD2O_46.74592     0\n",
            "CPMGD2O_93.4764      0\n",
            "CPMGD2O_119.88928    0\n",
            "CPMGD2O_264.14424    0\n",
            "dtype: int64\n",
            "NaNを含むターゲット変数の数: 0\n",
            "\n",
            "Trial 1/10 with parameters:\n",
            "{'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7dc4fce18950>, 'inv', 'neg', <gplearn.functions._Function object at 0x7dc54c92aed0>, <gplearn.functions._Function object at 0x7dc4fd500cd0>, <gplearn.functions._Function object at 0x7dc4fd7d7f90>, <gplearn.functions._Function object at 0x7dc54c71a410>, <gplearn.functions._Function object at 0x7dc4fd2b7690>, <gplearn.functions._Function object at 0x7dc50618e610>, <gplearn.functions._Function object at 0x7dc4fce18a10>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-f847ce53b390>:50: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "<ipython-input-3-f847ce53b390>:62: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-3-f847ce53b390>:62: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.75\n",
            "  Precision: 0.6666666666666666\n",
            "  Recall: 0.6666666666666666\n",
            "  F1-score: 0.6666666666666666\n",
            "  AUC: 0.7\n",
            "  Features: ['BCUT2D_MWHI', 'PEOE_VSA13', 'VSA_EState10', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'DSC_area', 'DSC_peak_height', 'MSEH2O_0.12992', 'CPMGD2O_119.88928']\n",
            "  Equation: abs(mul2(square(cbrt(VSA_EState10)), fr_Al_COO))\n",
            "  Parameters: {'tournament_size': 20, 'stopping_criteria': 0.0, 'population_size': 1000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 100, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x7dc4fce18950>, 'inv', 'neg', <gplearn.functions._Function object at 0x7dc54c92aed0>, <gplearn.functions._Function object at 0x7dc4fd500cd0>, <gplearn.functions._Function object at 0x7dc4fd7d7f90>, <gplearn.functions._Function object at 0x7dc54c71a410>, <gplearn.functions._Function object at 0x7dc4fd2b7690>, <gplearn.functions._Function object at 0x7dc50618e610>, <gplearn.functions._Function object at 0x7dc4fce18a10>]}\n"
          ]
        }
      ],
      "source": [
        "#20250502 for HNCO - スケーリング除去, カスタム関数複雑化2→修正版3\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込みと NaN 処理\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# NaN のチェック\n",
        "print(\"NaNを含む特徴量の数:\\n\", X.isnull().sum())\n",
        "print(\"NaNを含むターゲット変数の数:\", y.isnull().sum())\n",
        "\n",
        "# NaN の処理 (平均値で補完)\n",
        "X = X.fillna(X.mean())\n",
        "y = y.fillna(y.mean())\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def protected_cbrt(x):\n",
        "    return np.cbrt(x)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def protected_cube(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**3, np.sign(x) * 1e10)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10) # 無限大を大きな有限数に置換\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "cbrt_function = make_function(function=protected_cbrt, arity=1, name='cbrt')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "cube_function = make_function(function=protected_cube, arity=1, name='cube')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "# sqrt_function の定義は残しておいても問題ありませんが、function_set から削除します\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', log_function, 'inv', 'neg',\n",
        "                square_function, cbrt_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                cube_function, multiply3_function,\n",
        "                exp_function]\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [1000],\n",
        "    'generations': [100],\n",
        "    'tournament_size': [20],\n",
        "    'stopping_criteria': [0.0],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.05],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.01], # 少し大きめの値を設定\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 10\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train, y_train) # スケール前のデータを使用\n",
        "    X_test_sel = selector.transform(X_test) # スケール前のデータを使用\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogOsJfquj43v",
        "outputId": "39009068-112e-4dc6-eabe-84134c634025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gplearn in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-dd360756b308>:46: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
            "<ipython-input-11-dd360756b308>:55: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "<ipython-input-11-dd360756b308>:55: RuntimeWarning: invalid value encountered in log\n",
            "  return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 1/5 with parameters:\n",
            "{'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 200, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x78a04dc31750>, 'inv', 'neg', <gplearn.functions._Function object at 0x78a03597da50>, <gplearn.functions._Function object at 0x789fffd78f10>, <gplearn.functions._Function object at 0x789ff8ccdb10>, <gplearn.functions._Function object at 0x789ff8ccfc90>, <gplearn.functions._Function object at 0x78a04dc33010>]}\n",
            "\n",
            "Best Model Summary:\n",
            "  Accuracy: 0.75\n",
            "  Precision: 0.6666666666666666\n",
            "  Recall: 0.6666666666666666\n",
            "  F1-score: 0.6666666666666666\n",
            "  AUC: 0.7333333333333333\n",
            "  Features: ['BCUT2D_MWHI', 'PEOE_VSA13', 'VSA_EState10', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'DSC_area', 'DSC_peak_height', 'MSEH2O_0.12992', 'CPMGD2O_119.88928']\n",
            "  Equation: abs(inv(add(square(mul(CPMGD2O_119.88928, PEOE_VSA13)), inv(add(abs(mul(fr_Al_COO, VSA_EState10)), MSEH2O_0.12992)))))\n",
            "  Parameters: {'tournament_size': 5, 'stopping_criteria': 0.05, 'population_size': 5000, 'parsimony_coefficient': 0.01, 'p_subtree_mutation': 0.05, 'p_point_mutation': 0.05, 'p_hoist_mutation': 0.05, 'p_crossover': 0.85, 'n_features_to_select': 10, 'max_samples': 1.0, 'generations': 200, 'function_set': ['add', 'sub', 'mul', 'abs', <gplearn.functions._Function object at 0x78a04dc31750>, 'inv', 'neg', <gplearn.functions._Function object at 0x78a03597da50>, <gplearn.functions._Function object at 0x789fffd78f10>, <gplearn.functions._Function object at 0x789ff8ccdb10>, <gplearn.functions._Function object at 0x789ff8ccfc90>, <gplearn.functions._Function object at 0x78a04dc33010>]}\n"
          ]
        }
      ],
      "source": [
        "#20250506 for HNCO　スケーリング削除 カスタム関数シンプル化　再トライ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# from sklearn.preprocessing import StandardScaler # 削除\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('HNCO_RDKit_DSC_MSECPMGdryTop10_Features.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "# # 特徴量のスケーリング # 削除\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled_df = X_train.copy() # スケーリングしない場合は元のDataFrameをコピー\n",
        "X_test_scaled_df = X_test.copy()   # スケーリングしない場合は元のDataFrameをコピー\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10) # 無限大を大きな有限数に置換\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10) # 非正の値を大きな負の数に置換\n",
        "\n",
        "# make_function を使って GPlearn が認識できる形式に変換\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "# sqrt_function の定義は残しておいても問題ありませんが、function_set から削除します\n",
        "\n",
        "# 改善版：関数セットとパラメータ\n",
        "function_set = ['add', 'sub', 'mul', 'abs', log_function, 'inv', 'neg',\n",
        "                square_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                multiply3_function,\n",
        "                exp_function]\n",
        "\n",
        "param_grid_improved = {\n",
        "    'n_features_to_select': [10],\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [5000],\n",
        "    'generations': [200],\n",
        "    'tournament_size': [5],\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.85],\n",
        "    'p_subtree_mutation': [0.05],\n",
        "    'p_hoist_mutation': [0.05],\n",
        "    'p_point_mutation': [0.05],\n",
        "    'max_samples': [1.0],\n",
        "    'parsimony_coefficient': [0.01],\n",
        "   }\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5\n",
        "param_sampler = ParameterSampler(param_grid_improved, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "best_score = -1.0\n",
        "best_params = None\n",
        "best_estimator = None\n",
        "all_results = []\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\nTrial {i+1}/{n_iter} with parameters:\\n{params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    all_results.append({\n",
        "        'params': params,\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc': auc,\n",
        "        'r2_score': r2,\n",
        "        'features': selected_features,\n",
        "        'equation': str(est._program)\n",
        "    })\n",
        "\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_params = params\n",
        "        best_estimator = est\n",
        "        best_features = selected_features\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        best_auc = auc\n",
        "\n",
        "# ベストモデル結果\n",
        "print(\"\\nBest Model Summary:\")\n",
        "print(f\"  Accuracy: {best_score}\")\n",
        "print(f\"  Precision: {best_precision}\")\n",
        "print(f\"  Recall: {best_recall}\")\n",
        "print(f\"  F1-score: {best_f1}\")\n",
        "print(f\"  AUC: {best_auc}\")\n",
        "print(f\"  Features: {best_features}\")\n",
        "print(f\"  Equation: {best_estimator._program}\")\n",
        "print(f\"  Parameters: {best_params}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPCYaOJ/2ltNt9m5vCfBsI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}